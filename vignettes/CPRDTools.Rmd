---
title: "CPRDTools: a CPRD GOLD data wrangling toolkit"
output: pdf_document
document: arctile
author: James C. F. Schmidt
bibliography: CPRDTools_ref.bib
abstract: The analysis of large scale data, and moreover the analysis of large scale electronic health records data is become more commonplace. The ease and ability of modern data generation and capture means there is the potential across almost all industries to capture more data now, than ever before and that equates to large data resources, with CPRD no exception. These large data resources, as attractive and appealing as they may be to researchers, pose a significant problem - how to manage all that data? `CPRDTools` is a collection of wrapper R functions intended to simplify the loading, extraction and management of Clinical Practice Research Datalink (CPRD) GOLD specific and associated electgronic health records data. Allowing for the loading of CPRD and non-CPRD data into a SQLite based database, providing an efficient, secure and updatable repository for the data, keeing the origional source files intact. Through data queries, user-defined data are drawn allowing for subsetting, joining and filtering in a signle step, creating alaysis ready data.
    
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

# Introduction

The CPRD is one of the largest longitudinal medical records databases in the world, supported by the National Institute of Health (NIHR) and the Medicines and Healthcare products Regulatory Agency (MHRA). It was first established in 1987 as the Value Added Medical Products (VAMP) dataset, this grew into the General Practice Research Database (GPRD) in 1993, before its final transition into CPRD in 2012 [@Herrett2015].

PRD GOLD data are comprised of ten separate datasets: patient, practice, staff, consultation, clinical, additional clinical details, referral, immunisation, test and therapy [@Padmanabhan2017]. These datasets contain their specific data and are linkable through a unique linkage key field, where key does not imply importance but a unique variable contained in two datasets allowing them to be joined, such as the CPRD-assigned and anonymised unique patient identifier `patid`.

Due to the size of CPRD, data extracted for research are spread over multiple text (`.txt`) files within each dataset to enable file transfer. This means that for CPRD clinical data, for instance, a researcher may receive their requested clinical data broken up over 25 individual text files. This is done to aid with file completeness and reduce turn-around times if errors are found. If an error occurred during the transfer of data between the data owner and the researcher or in the extraction of the requested data by the data owner, the error can potentially be limited to only select files, requiring only their replacement with the corrected/error-free versions. 

Often these text files are additionally zipped, or compressed, requiring that these files first be uncompressed or unzipped. These multiple files from each dataset (clinical, referral etc.) then need to be grouped together and amalgamated into a single `table`. Tables are a collection of data of the same shape, from the same dataset. In CPRD, each separate dataset (patient, practice, clinical etc.) forms a table. These tables are then stored in the SQLite database.

SQLite is an opensource, SQL based database engine [@sqlite]. The use of a SQLite database provides an efficient storage solution, allowing for the loading, updating and maintenance of the database, all while retaining the original *raw* data files unaltered. An SQlite database permits for rapid data extraction through the use of data queries, drawing the required data from the database, allowing filtering, sub-setting, limiting and the joining of data in a single execution step.   

This document aims to provide a simple and introductory overview of `CPRDTools` and its application to arbitrary (fictional) data. This data though are provided in the manner in which many CPRD data extract are received, where data are spread over multiple files and often located in sub-folders.

`CPRDTools` are loaded using:
```{r, message=FALSE}
library(devtools)
install_github("JamesCFSchmidt/CPRDTools")
library(CPRDTools)
```

# CPRDTools overview

The functions within 'CPRDTools' broadly fall into three groups, categorised by their general application area: (1) - loading, (2) - maintenance and other tasks and (3) - extraction. **Loading** encompasses all functions used in the reading, converting and writing of data into the database including a function used to list all available files and all available CPRD files in a specified location, functions used in database maintenance, query speed improvements and date conversion functions fall under **maintenance and other tasks**, and finally, functions used to, and in the process of, drawing and retrieving data from the database fall within **extraction**.

## The data

The example data supplied with this package resembles CPRD GOLD data in layout and in file naming convention. Additionally included are example secondary files from 'Hospital Episode Statistics' (HES) patient information and 'Office for National Statistics' (ONS) actuarial life tables. The location of the file and the location where the database will be build must be provided
```{r, include=FALSE}
#database location
DB.path = "/home/j/jcfs2/Documents/Test"
#location of example data
FILE.path = dirname(system.file("extdata", "hes_patient_20336R.txt", package = "CPRDTools"))
```

## Loading

Before loading any data into the database, it is best practice to understand the layout of the *raw* data. This can be achieved by either navigating to the location where the data are stored or by employing the `list_files` and `list_cprd` functions. 

### Listing available data

The `list_files` function provides a list of all files of a specified type in a specified location. To view all text (`.txt`) files in the data location
```{r}
list_files(file_location = FILE.path,
           file_type = ".txt")
```
To view all compressed/*zipped* (`.zip`) files in the data location
```{r}
list_files(file_location = FILE.path,
           file_type = ".zip")
```           
And to view all files in the data location, excluding files in sub-folders
```{r}
list_files(file_location = FILE.path,
           file_type = "all")
```

From the above it can be seen that there are six zipped text files (`.zip`), one excel file (`.xlsx`), one standard text file (`.txt`) and a folder, `patient`.
In order to view CPRD GOLD specific files, corresponding to names CPRD GOLD datasets (*patient, practice, staff, consultation, clinical, additional clinical details, referral, immunisation, test and therapy*), the `list_cprd` function is used. This function provides the core functionality to the loading of CPRD GOLD data, generating a list of CPRD GOLD specific files in the specified location.
```{r}
list_cprd(file_location = FILE.path,
          folder = F, 
          zip = T)
```
Here the folders input is defined as `r FALSE`, showing only zipped data contained in the data location specified. When the folder input is `r TRUE`, the available data found in the `patient` folder is displayed.
```{r}
list_cprd(file_location = FILE.path,
          folder = T, 
          zip = T)
```
In the `$table` output, the `list_cprd` function defines the tables and the count of *raw* files associated with that table in the data location. This outputted list is core to the automated loading of CPRD data, using the tables and files in each table to load all or a selection of specified CPRD GOLD files.  

### Loading all available data

The `load_cprd` function, relying on the `list_cprd` function for file and table list from a specified data location is able to automatically load in a selection or all available CPRD GOLD files in a specified location. Importing, uncompressing (unzipping) and appending all files from a CPRD GOLD-specific table into a database.

To load the `patient` data into a new database, the `load_cprd` function is defined as 
```{r}
load_cprd(db_path = DB.path, 
          file_location = FILE.path, 
          tables_to_load = "Patient", 
          folder = T, 
          zip = T, 
          load_mapping = T, 
          overwrite = F)
```
The `patient` data are found in a sub-folder within the data location (`r folder=T`) and the data are compressed (`r zip=T`). As this is a new load of the database, no overwriting is required (`r overwrite=F`) and no CPRD specific mapping is needed (`r load_mapping=F`).

Alternatively to specifying each individual table to load (*additional, clinical, consultation, immunisation, patient, practice, referral, staff, test, therapy*), the specification of the loading of *all* tables can be performed.
```{r, eval=FALSE}
load_cprd(db_path = DB.path, 
          file_location = FILE.path, 
          tables_to_load = "all", 
          folder = F, 
          zip = T, 
          load_mapping = F, 
          overwrite = F)
```
This returns an error
```{r, echo=FALSE, error=TRUE}
load_cprd(db_path = DB.path, 
          file_location = FILE.path, 
          tables_to_load = "all", 
          folder = F, 
          zip = T, 
          load_mapping = F, 
          overwrite = F)
```
The error is due to the `patient` table already being contained in the database. The `r tables_to_load = "all"` should only be applied on new databases or in conjunction with `r overwrite = F`.
The remainder of the CPRD GOLD data are loaded with
```{r}
load_cprd(db_path = DB.path, 
          file_location = FILE.path, 
          tables_to_load = c("Clinical","Practice"), 
          folder = F, 
          zip = T, 
          load_mapping = F, 
          overwrite = F)
```
 The `$loaded_tables` output shows the current tables loaded and available in the database `
 
### Loading a single CPRD table

The `patient` table previously could have been loaded singularly using the `load_table` function. Similar to the `load_cprd` function, this will load CPRD-specific data tables, using the compiled list of available files and their respective tables generated in the `list_cprd` function. This function imports, unzips and appends the files specific to a CPRD GOLD table but performs the task on a single table at a time. 

This may be of use when the data are stored in separate file locations, not within sub-folders in the same data location. The loading of the `practice` information is performed using
```{r}
load_table(db_path = DB.path,
           file_location = FILE.path,
           table_name = "Practice",
           zip = T,
           overwrite = T)
```
Here `r overwrite=T` as the practice table was previously loaded.

### Updating a CPRD GOLD table

If you were to receive a new month or year of `patient` data, this would be appened to the data already contained in the database using
```{r, eval=FALSE}
update_table(db_path = DB.path,
             file_location = "/rfs/LRWE_Proj59/jcfs2/Test/patient/305508.ms1_Extract_Patient_001.zip",
             table_name = "PaTient")
```
Note that capitalisation of the table name for CPRD-specific tables in unimportant. In general, SQL and therefore SQLite is not case sensitive. 

### Updating an additional file

For peripheral or additional data, whether CPRD or non-CPRD specific, the use of the `load_additional` function is employed. This function loads a singular file into a table (new or existing). 
```{r}
load_additional(db_path = DB.path,
                file_location = "/rfs/LRWE_Proj59/jcfs2/Test/hes_patient_19_253R.txt",
                type = ".txt",
                table_name = "hes_patient",
                overwrite = F)
```
The accepted files types are `.txt, .csv, .dta, .rds, .excel, .xl, .xls` and `.xlsx` with no additional input for file importing.

### Updating an additional file

If sub-setting, manipulation or sheet selection, for instance, is required prior to the loading of a file into a table (new or existing) is required, it is first recommended to import the file in the usual manner into R. Once the data are in the format and layout that is required, the `load_global` function can be employed
```{r}
## first import the life table data from .csv
life_table <- read.csv("/rfs/LRWE_Proj59/jcfs2/Database/Final.Datasets/ons_lt.csv")
##sub-set the data to the required fields
life_table <- life_table[,c("gender","year","age","pop_rate")]
## load into database
load_global(db_path = DB.path,
            file_to_load = life_table,
            table_name = "Life_table",
            overwrite = F)
```

## Extracting

With the database successfully loaded with our CPRD GOLD and associated data, we are now able to perform data extracts from the database. Before executing data extracts, it is *best practice* to first interrogate the databases for loaded table (ignoring that this is provided after each load iteration previously) and the for the structure and layout of a selection of tables.

### List tables, fields and first rows

In order to list all loaded tables in the database, similar to the output in the `$loaded_tables`, returned when loading data via the data-loading function previously, specify
```{r}
db_tables(db_path = DB.path)
```
loaded are the `Clinical`, `Patient`, `Practice` and `hes_patient` tables. 

To view the fields within the `Patient` table
```{r}
table_fields(db_path = DB.path,
             table_name = "PaTient")
```

To view the first 5 row of the `hes_patient` table
```{r}
first_n(db_path = DB.path,
        table_name = "hes_patient",
        n = 5)
```

### Extracting data

Data extraction can be performed via two functions (1) the user-input defined `query_builder` function and (2) `query_direct`, the more customisable and preferred method of data extraction.

The basic structure of the `query_bilder` function is
```{r, eval=FALSE}
query_builder(db_path,
              unique_obs,
              field_list,
              from_table,
              join_table,
              join_fields,
              join_type,
              join_on,
              where_table,
              where_filter,
              order_column,
              order_type,
              limit_to)
```
This function allows for only a simple join between two tables, the main table (`from_table`) and secondary table (`join_table`). Fields can be extracted from both tables, including the field used to join the tables together (`join_on`), known as a *key* field. Additional filtering, sub-setting and restrictions of data can be done using where, order and limit inputs.

A simple extract is defined as
```{r}
query_builder(db_path = DB.path,
              unique_obs = T, 
              field_list = c("patid","gender","yob","deathdate"),
              from_table = "Patient",
              join_table = "hes_patient",
              join_fields = c("gen_hesid","match_rank"),
              join_on = "patid",
              limit_to = 5)
```
Here, a unique extract of `patid`, `gender`, `yob` and `deathdate` from the `Patient` table and `gen_hesid` and `match_rank` from the `hes_patient` table are extracted, joined together via the `patid` field and limited to the first 10 rows of outputted data. 
This data can be returned directly into a dataset using
```{r, eval=FALSE}
data <- query_builder(db_path = DB.path,
                      unique_obs = T, 
                      field_list = c("patid","gender","yob","deathdate"),
                      from_table = "Patient",
                      join_table = "hes_patient",
                      join_fields = c("gen_hesid","match_rank"),
                      join_on = "patid",
                      limit_to = 5)&query_data
```

Building on the previous extract, now filtered for only `gender==1` and ordered by `patid` in ascending order is defined as
```{r}
query_builder(db_path = DB.path,
              unique_obs = T, 
              field_list = c("paTid","gender","yob","deathdate"),
              from_table = "Patient",
              join_table = "hes_patient",
              join_fields = c("gen_hesid","match_rank"),
              join_type = "Left",
              join_on = "patiD",
              where_table = "PatieNt",
              where_filter = "geNder==1",
              order_field = "PATID",
              order_type = "aSC",
              limit_to = 5)
```
Note that SQLite is not case sensitive. 

The preferred method for data extraction is through the direct execution of SQL code defined by the user. This allows for the most customisable, comprehensive and completed data extraction, providing all the functionality found in a SQLite $\color{blue}{\texttt{SELECT}}$ statement. 

A introductory overview of the $\color{blue}{\texttt{SELECT}}$ statement can be found at https://www.sqlitetutorial.net/sqlite-select/2, with the basic syntax defined as

```{sql, eval=FALSE}
SELECT DISTINCT column_list
FROM table_list
  JOIN table ON join_condition
WHERE row_filter
ORDER BY column
LIMIT count OFFSET offset
GROUP BY column
HAVING group_filter;
```

To replicate the query executed using the `query_builder` function previously, the following is provided
```{r}
query_direct(db_path = DB.path,
             query = "SELECT DISTINCT Patient.patid, 
                                      Patient.gender, 
                                      Patient.yob, 
                                      Patient.deathdate, 
                                      hes_patient.gen_hesid, 
                                      hes_patient.match_rank 
                      FROM Patient 
                      LEFT JOIN hes_patient ON hes_patient.patid = Patient.patid
                      LIMIT 5 ;")
```
The `query` here is identical to the query returned in the `$query` output in the `query_builder` function. The table from which a field should be extracted is provided before the field such as `patient.yob`, extracting `yob` from `Patient`.

This query can be made more aesthetically pleasing by using an alias for the `Pateint` and `hes_patient` tables
```{r}
query_direct(db_path = DB.path,
             query = "SELECT DISTINCT pat.patid, 
                                      pat.gender as sex, 
                                      pat.yob as bith_date, 
                                      pat.deathdate as death, 
                                      hes.gen_hesid as hesid, 
                                      hes.match_rank 
                      FROM Patient pat
                      LEFT JOIN hes_patient hes ON hes.patid = pat.patid
                      LIMIT 5 ;")$query_data
```

To view the procedure in which a query will be executed, use $\color{blue}{\texttt{EXPLAIN QUERY PLAN}}$. This will provide an overview of the strategy or plan SQLite will use to execute a SQL query, providing
```{r}
query_direct(db_path = DB.path,
             query = "EXPLAIN QUERY PLAN
                      SELECT DISTINCT pat.patid, 
                                      pat.gender as sex, 
                                      pat.yob as bith_date, 
                                      pat.deathdate as death, 
                                      hes.gen_hesid as hesid, 
                                      hes.match_rank 
                      FROM Patient pat
                      LEFT JOIN hes_patient hes ON hes.patid = pat.patid
                      LIMIT 5 ;")$query_data
```
Shows that first a full-table scan is used on the `Patient` table, followed by a subset search of the `hes_patient` table followed by a temporary b-tree structure used to defined the unique ($\color{blue}{\texttt{DISTINCT}}$) output data. A more complete overview of the $\color{blue}{\texttt{EXPLAIN QUERY PLAN}}$ command can be found at https://www.sqlite.org/eqp.html.

## Maintenace and other tasks

The removal and remaining of tables and the deletion of the databases, as well as query speed improvement function make up the final section  of the `CPRDTools` package. 

### Speeding up a query
A method to improve the execution times of a query is indexing. Indexing a table or dataset creates a secondary data table containing the indexing variable and the row number (`rowid`) associated with that number. The index is initially search, returning the row numbers for the searched fields, before using these row numbers to return the required data from.

Consider the following query, returning data from the `Patient` and `Clinical` tables, where the `{sql} medcodes IN (1004,1046,1076,1146,1157,1314,1425,1454,1508,1842)`, defined as
```{r}
query_direct(db_path = DB.path,
             query = "EXPLAIN QUERY PLAN
             SELECT pat.patid,
                    pat.yob,
                    pat.deathdate,
                    clin.eventdate,
                    clin.medcode
             FROM Patient pat 
             INNER JOIN Clinical clin ON 
                   pat.patid = clin.patid
             WHERE clin.medcode IN 
             (1004,1046,1076,1146,1157,
              1314,1425,1454,1508,1842);")
```
Executing the $\color{blue}{\texttt{EXPLAIN QUERY PLAN}}$ command provides 
```{r, echo=FALSE}
query_direct(db_path = DB.path,
             query = "EXPLAIN QUERY PLAN
             SELECT pat.patid,
                    pat.yob,
                    pat.deathdate,
                    clin.eventdate,
                    clin.medcode
             FROM Patient pat 
             INNER JOIN Clinical clin ON 
                   pat.patid = clin.patid
             WHERE clin.medcode IN 
             (1004,1046,1076,1146,1157,
              1314,1425,1454,1508,1842);")$query_data
```
Using a full-table scan of the clinical table for the desired `medcodes` before using an automatically generated, temporary index on `patid`.

An index can be defined on the `clinical` table using the `medcodes` as 
```{r}
add_index(db_path = DB.path,
          index_name = "clinical_index",
          index_table = "clinical",
          index_field = "medcode")
```

Now the query plan shows 
```{r, echo=FALSE}
query_direct(db_path = DB.path,
             query = "EXPLAIN QUERY PLAN
             SELECT pat.patid,
                    pat.yob,
                    pat.deathdate,
                    clin.eventdate,
                    clin.medcode
             FROM Patient pat 
             INNER JOIN Clinical clin ON 
                   pat.patid = clin.patid
             WHERE clin.medcode IN 
             (1004,1046,1076,1146,1157,
              1314,1425,1454,1508,1842);")$query_data
```
First using the `clinical_index` to retrieve the desired `medcodes` before completing the rest of the query. The speed improvements are dependent on the complexity of the data, the query and the size of the data. There is a once-off execution time cost in indexing data but for large, complex datasets where queries rely on searching lists of medical codes, for instance, this may be beneficial to the user.

If a SQL statement must be passed directly to the database, specifically for maintenance or speed improvements, the `statement_direct` function is used. If the index created previously were to be deleted, the following is used
```{r}
statement_direct(db_path = DB.path,
                 statement = "DROP INDEX clinical_index;")
```
`statement_direct` provides no output data and so should only be used for maintenance and speed improvement tasks such as $\color{blue}{\texttt{UPDATE, DELETE, INSERT INTO, DROP TABLE}}$ etc.

### Convert fields to dates
Often date fields are provided in datasets in the format of a date ('12/03/1989') but read as a character variable into the database. To convert a field to a date field use
```{r}
data <- query_direct(db_path = DB.path,
                     query = "SELECT* FROM Practice;")$query_data
str(data)
convert_data <- convert_dates(data = data,
                              date_fields = c("lcd","uts"),
                              format = "%Y-%m-%d")$convert_data
str(convert_data)
```
Here the format provided is the format the fields are prior to conversion and not the desired output required, with the default set to '%d/%m/%Y'.

### Maintenance
in order to rename a table in the database, use
```{r}
rename_table(db_path = DB.path,
             old_name = "practice",
             new_name = "gp_pracs")
```

While to remove an entire table from the database, the following is used
```{r}
delete_table(db_path = DB.path, 
           remove_tables = "gp_pracs")
```

For the complete deletion of a database, use with caution 
```{r, eval =FALSE}
delete_db(db_path = DB.path)
```
This will require the inputting of confirmation of the deletion into the `Console`
```{r, echo=FALSE}
message(cat(crayon::red("----------WARNING, DELETION IN PROGRESS----------\n")))
message(cat(crayon::blue("Press y+[enter] to proceed, n+[enter] to stop:\n")))
```

# Conclusion
`CPRDTools` provides a comprehensive set of function to aid the general loading, maintenance and extraction of CPRD GOLD and its associated and peripheral data. These functions should provide a *toolkit* to any researcher, aiding in there ability to self-manage their data using an efficient and reliable SQLite data repository, providing tools to view, interrogate, load, extract, maintain, convert and delete in a single package.  

# References
